{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112281,"databundleVersionId":13445283,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:37:49.414901Z","iopub.execute_input":"2025-08-20T08:37:49.415190Z","iopub.status.idle":"2025-08-20T08:37:54.311789Z","shell.execute_reply.started":"2025-08-20T08:37:49.415171Z","shell.execute_reply":"2025-08-20T08:37:54.311045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install terratorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:31:30.597215Z","iopub.execute_input":"2025-08-20T08:31:30.597405Z","iopub.status.idle":"2025-08-20T08:34:52.433031Z","shell.execute_reply.started":"2025-08-20T08:31:30.597388Z","shell.execute_reply":"2025-08-20T08:34:52.432160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations\nfrom albumentations.pytorch import ToTensorV2\nimport lightning.pytorch as pl\nfrom lightning.pytorch.loggers import TensorBoardLogger\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nfrom terratorch.datamodules import GenericNonGeoSegmentationDataModule\nfrom terratorch.tasks import SemanticSegmentationTask\nimport zipfile\nimport glob\nimport os\nimport numpy as np\nimport rasterio\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:34:58.897024Z","iopub.execute_input":"2025-08-20T08:34:58.897730Z","iopub.status.idle":"2025-08-20T08:35:38.303570Z","shell.execute_reply.started":"2025-08-20T08:34:58.897694Z","shell.execute_reply":"2025-08-20T08:35:38.302953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_path = '/kaggle/input/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/'\n\ndatamodule = GenericNonGeoSegmentationDataModule(\n    batch_size=4,\n    num_workers=2,\n    num_classes=6,\n\n    # Define dataset paths\n    train_data_root=dataset_path+'/train/inputs',\n    train_label_data_root=dataset_path+'/train/labels',\n    val_data_root=dataset_path+'/val/inputs',\n    val_label_data_root=dataset_path+'/val/labels',\n    test_data_root=dataset_path+'/test/inputs',\n    # test_label_data_root=dataset_path+'/test/labels',\n    \n    #data set path for infereencing on test input\n    predict_data_root=dataset_path+'test/inputs',\n \n    # Define splits\n    train_split=\"/kaggle/input/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/train.txt\",\n    val_split=\"/kaggle/input/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/val.txt\",\n    test_split=\"/kaggle/input/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/track1-india-al-impact-gen-ai-hackathon/test.txt\",\n\n    img_grep='*input.tif',\n    label_grep='*label_c6.tif',\n\n    train_transform=[\n        albumentations.D4(),\n        ToTensorV2(),\n    ],\n    val_transform=None,\n    test_transform=None,\n    means = [43.377114, 38.762922, 37.587551, 39.397895, 42.61577, 54.785745, 63.259959, 59.998601, 13.367036, 69.212995, 48.322503, 69.708629],\n    stds = [3.335747, 4.160813, 5.434037, 9.239101, 8.014329, 6.745426, 8.070073, 7.844921, 2.563382, 16.967517, 15.586694, 9.258978],\n    no_data_replace=0,\n    no_label_replace=-1,\n)\n\n\ndatamodule.setup(\"fit\")\ndatamodule.setup(\"predict\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:51:02.961047Z","iopub.execute_input":"2025-08-20T08:51:02.961587Z","iopub.status.idle":"2025-08-20T08:51:03.044512Z","shell.execute_reply.started":"2025-08-20T08:51:02.961562Z","shell.execute_reply":"2025-08-20T08:51:03.043773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"Train set size:\", len(datamodule.train_dataset))\nprint(\"Validation set size:\", len(datamodule.val_dataset))\n\ndatamodule.setup(\"test\")\nprint(\"Test set size:\", len(datamodule.test_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:52:28.973039Z","iopub.execute_input":"2025-08-20T08:52:28.973580Z","iopub.status.idle":"2025-08-20T08:52:28.983153Z","shell.execute_reply.started":"2025-08-20T08:52:28.973552Z","shell.execute_reply":"2025-08-20T08:52:28.982593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plotting a few samples\ndatamodule.val_dataset.plot(datamodule.val_dataset[10])\n#print(datamodule.val_dataset[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:52:39.867090Z","iopub.execute_input":"2025-08-20T08:52:39.867637Z","iopub.status.idle":"2025-08-20T08:52:40.707759Z","shell.execute_reply.started":"2025-08-20T08:52:39.867615Z","shell.execute_reply":"2025-08-20T08:52:40.706957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nOUT_DIR = \"/kaggle/working\"\n\nBATCH_SIZE = 16\nEPOCHS = 1\nLR = 1e-5\nWEIGHT_DECAY = 0.1\nHEAD_DROPOUT = 0.1\nFREEZE_BACKBONE = False\n\nBANDS =[1,2,3,4,5,6,7,8,9,10,11,12]\nNUM_FRAMES = 1\n\n#      Crop     Pixel_total    Pixel_percentage Class_weight\n#      Gram        2545             1.73       0.4761\n#     Maize        7128             4.84       0.1702\n#   Mustard       36362            24.67       0.0334\n# Sugarcane        4542             3.08       0.2674\n#     Wheat       59585            40.42       0.0204\n# OtherCrop       37247            25.27       0.0326\n\nCLASS_WEIGHTS = [0.4761, 0.1702, 0.0334, 0.2674, 0.0204, 0.0326]\n\nSEED = 0\npl.seed_everything(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:52:45.556879Z","iopub.execute_input":"2025-08-20T08:52:45.557404Z","iopub.status.idle":"2025-08-20T08:52:45.566500Z","shell.execute_reply.started":"2025-08-20T08:52:45.557379Z","shell.execute_reply":"2025-08-20T08:52:45.565704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED = 0\n\npl.seed_everything(SEED)\n\n# Logger\nlogger = TensorBoardLogger(\n    save_dir=OUT_DIR,\n    name=\"cropid\",\n)\n\n# Callbacks\ncheckpoint_callback = ModelCheckpoint(\n    monitor=\"val/Multiclass_Jaccard_Index\",\n    mode=\"max\",\n    dirpath=os.path.join(OUT_DIR, \"cropid\", \"checkpoints\"),\n    filename=\"best-checkpoint-{epoch:02d}-{val_loss:.2f}\",\n    save_top_k=1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:53:17.060010Z","iopub.execute_input":"2025-08-20T08:53:17.060590Z","iopub.status.idle":"2025-08-20T08:53:17.066766Z","shell.execute_reply.started":"2025-08-20T08:53:17.060564Z","shell.execute_reply":"2025-08-20T08:53:17.066170Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trainer\ntrainer = pl.Trainer(\n    accelerator=\"auto\",\n    strategy=\"auto\",\n    devices=\"auto\",\n    precision=\"16-mixed\",\n    num_nodes=1,\n    logger=logger,\n    max_epochs=EPOCHS,\n    check_val_every_n_epoch=1,\n    log_every_n_steps=10,\n    enable_checkpointing=True,\n    callbacks=[checkpoint_callback],\n    limit_predict_batches=1,  # predict only in the first batch for generating plots\n)\n\n# DataModule\ndata_module = datamodule\n\n\n# Model\n\nbackbone_args = dict(\n    backbone_pretrained=True,\n    backbone=\"prithvi_eo_v2_300_tl\", # prithvi_eo_v2_300, prithvi_eo_v2_300_tl, prithvi_eo_v2_600, prithvi_eo_v2_600_tl\n    #backbone_coords_encoding=[\"time\", \"location\"],\n    backbone_bands=BANDS,\n    backbone_num_frames=1, # 1 is the default value,\n)\n\ndecoder_args = dict(\n    decoder=\"UperNetDecoder\",\n    decoder_channels=256,\n    decoder_scale_modules=True\n)\n\nnecks = [\n    dict(\n            name=\"ReshapeTokensToImage\",\n            effective_time_dim=NUM_FRAMES,\n        )\n    ]\n\nmodel_args = dict(\n    **backbone_args,\n    **decoder_args,\n    num_classes=6,\n    head_dropout=HEAD_DROPOUT,\n    necks=necks,\n    rescale=True\n)\n    \n\nmodel = SemanticSegmentationTask(\n    model_args=model_args,\n    plot_on_val=False,\n    class_weights=CLASS_WEIGHTS,\n    loss=\"dice\",\n    lr=LR,\n    optimizer=\"AdamW\",\n    optimizer_hparams=dict(weight_decay=WEIGHT_DECAY),\n    freeze_backbone=FREEZE_BACKBONE,\n    freeze_decoder=False,\n    model_factory=\"EncoderDecoderFactory\",\n    ignore_index = -1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:53:20.386728Z","iopub.execute_input":"2025-08-20T08:53:20.387232Z","iopub.status.idle":"2025-08-20T08:53:26.270261Z","shell.execute_reply.started":"2025-08-20T08:53:20.387210Z","shell.execute_reply":"2025-08-20T08:53:26.269445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrainer = pl.Trainer(\n    accelerator=\"auto\",\n    strategy=\"auto\",\n    devices=\"auto\",\n    precision=\"16-mixed\",\n    num_nodes=1,\n    logger=logger,\n    max_epochs=EPOCHS,\n    check_val_every_n_epoch=1,\n    log_every_n_steps=10,\n    enable_checkpointing=True,\n    callbacks=[checkpoint_callback],\n    limit_predict_batches=1,\n)\n\ntrainer.fit(model, datamodule=datamodule)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:53:39.136932Z","iopub.execute_input":"2025-08-20T08:53:39.137491Z","iopub.status.idle":"2025-08-20T08:53:39.187375Z","shell.execute_reply.started":"2025-08-20T08:53:39.137461Z","shell.execute_reply":"2025-08-20T08:53:39.186873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncheckpoint_dir = \"/kaggle/working/cropid/checkpoints\"\ncheckpoint_files = glob.glob(os.path.join(checkpoint_dir, \"best-checkpoint-*.ckpt\"))\n\nif len(checkpoint_files) == 0:\n    raise FileNotFoundError(\"No best checkpoint file found in the directory.\")\n    \n# Use the first match\nbest_ckpt_path = checkpoint_files[0]\n# test_results = trainer.test(model, datamodule=datamodule, ckpt_path=best_ckpt_path)\n# print(test_results)\nprint(best_ckpt_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:53:47.027604Z","iopub.execute_input":"2025-08-20T08:53:47.028084Z","iopub.status.idle":"2025-08-20T08:53:47.033030Z","shell.execute_reply.started":"2025-08-20T08:53:47.028058Z","shell.execute_reply":"2025-08-20T08:53:47.032487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A. Saving predictions on test input images  \n \n# Prediction on predict_data_root (see dataloader part)\npreds = trainer.predict(model, datamodule=datamodule, ckpt_path=best_ckpt_path)\n\noutput_dataset_path = \"/kaggle/working/\"\n# Output directory to save prediction tif files\noutput_dir = os.path.join(output_dataset_path, \"test_pred\")\nos.makedirs(output_dir, exist_ok=True)\n \n# Loop over batches\nfor batch_idx, batch in enumerate(preds):\n    tensor = batch[0][0]    # shape [4, 256, 256] → 4 images in this batch\n    file_paths = batch[1]   # list of file paths for this batch\n \n    for i in range(tensor.shape[0]):  # loop over each file in batch\n        arr = tensor[i].cpu().numpy().astype('int32')  # shape [256, 256] → single band\n \n        ref_path = file_paths[i]\n        with rasterio.open(ref_path) as src_ref:\n            ref_crs = src_ref.crs\n            ref_transform = src_ref.transform\n \n        out_name = os.path.splitext(os.path.basename(ref_path))[0] + \"_pred.tif\"\n        out_path = os.path.join(output_dir, out_name)\n \n        with rasterio.open(\n            out_path,\n            \"w\",\n            driver=\"GTiff\",\n            height=arr.shape[0],\n            width=arr.shape[1],\n            count=1,\n            dtype=arr.dtype,\n            crs=ref_crs,\n            transform=ref_transform\n        ) as dst:\n            dst.write(arr, 1)\n \n        print(f\"Saved {out_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:54:04.067395Z","iopub.execute_input":"2025-08-20T08:54:04.068150Z","iopub.status.idle":"2025-08-20T08:54:14.374504Z","shell.execute_reply.started":"2025-08-20T08:54:04.068123Z","shell.execute_reply":"2025-08-20T08:54:14.373732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## This is about model prediction on test input images and then create prediction for submission\n \n# A. Saving predictions on test input images  \n# B. Generating the submission file (`prediction.csv`) using the mask and prediction TIFFs  \n\n# Input directories\ndir_pred = os.path.join(output_dataset_path, \"test_pred\")\ndir_mask = os.path.join(dataset_path, \"test/labels\")\nprediction_csv = os.path.join(output_dataset_path, \"prediction.csv\")\n \nrecords = []\n \n# Get prediction files\npred_files = glob.glob(os.path.join(dir_pred, \"*.tif\"))\n \nfor pred_file in pred_files:\n    base_name = os.path.basename(pred_file)\n    mask_file = os.path.join(dir_mask, base_name.replace(\"input_pred.tif\", \"label_mask.tif\"))\n    \n    if not os.path.exists(mask_file):\n        print(f\"No mask found for {base_name}, skipping\")\n        continue\n \n    # Read prediction\n    with rasterio.open(pred_file) as src_pred:\n        pred_data = src_pred.read(1)\n \n    # Read mask\n    with rasterio.open(mask_file) as src_mask:\n        mask_data = src_mask.read(1)\n \n    # Apply mask (only keep pixels where mask == 1)\n    valid_idx = np.where(mask_data == 1)\n \n    # Pixel IDs\n    pixel_ids = np.ravel_multi_index(valid_idx, pred_data.shape)\n \n    # Predictions on masked pixels\n    masked_preds = pred_data[valid_idx]\n \n    # For each class (0–5)\n    for cls in range(6):\n        # Select pixels belonging to this class\n        cls_pixels = pixel_ids[masked_preds == cls]\n \n        if cls_pixels.size > 0:\n            # Format as \"pixel_id class\" pairs\n            pred_str = \" \".join(f\"{pid} {cls}\" for pid in cls_pixels.tolist())\n        else:\n            pred_str = \"\"\n \n        # Remove \"_input_pred.tif\" and add class as suffix\n        file_id = base_name.replace(\"_input_pred.tif\", f\"_{cls}\")\n \n        records.append([file_id, pred_str])\n \n# Create df\ndf = pd.DataFrame(records, columns=[\"id\", \"label\"])\n                  \n# fill empty/NA with \"0\"\ndf[\"label\"] = df[\"label\"].fillna(\"0\")\n\n# Save CSV\n# df.to_csv(prediction_csv, index=False, sep=\"\\t\")\ndf.to_csv(prediction_csv, index=False)\n\nprint(f\"Saved predictions to {prediction_csv}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T08:56:27.948850Z","iopub.execute_input":"2025-08-20T08:56:27.949487Z","iopub.status.idle":"2025-08-20T08:56:28.006351Z","shell.execute_reply.started":"2025-08-20T08:56:27.949463Z","shell.execute_reply":"2025-08-20T08:56:28.005740Z"}},"outputs":[],"execution_count":null}]}